import streamlit as st
import google.generativeai as genai
import os

# --- ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö ---
st.set_page_config(
    page_title="ZEDA.AI",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- ‡πÇ‡∏Ñ‡πâ‡∏î CSS ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤ ---
st.markdown("""
<style>
/* ‡∏ã‡πà‡∏≠‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á Streamlit ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ */
.st-emotion-cache-1cypcdb {
    visibility: hidden;
}
.st-emotion-cache-13ln4jf {
    background-color: #0E1117;
}

/* ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á sidebar */
.st-emotion-cache-12t9085 {
    background-color: #121212;
    padding-top: 5rem;
}
.st-emotion-cache-12t9085 a {
    color: #FAFAFA;
    font-weight: bold;
}
.st-emotion-cache-12t9085 .st-emotion-cache-1ky926a {
    background-color: #262626;
    border-radius: 10px;
}

/* ‡∏™‡πÑ‡∏ï‡∏•‡πå‡∏Å‡∏•‡πà‡∏≠‡∏á‡πÅ‡∏ä‡∏ó */
.st-emotion-cache-13ejs5a {
    background-color: #212121;
    border-radius: 15px;
    border: none;
}
.st-emotion-cache-1aehpbu {
    background-color: #0E1117;
}
</style>
""", unsafe_allow_html=True)

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡πâ‡∏î AI ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å ---
genai.configure(api_key=os.environ.get("GOOGLE_API_KEY"))
model = genai.GenerativeModel("gemini-2.5-flash")

# Sidebar
with st.sidebar:
    st.image("https://i.ibb.co/L50HjHj/ZEDA-AI.png", use_column_width=True) # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô URL ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
    st.markdown("## zeda0.5")
    st.markdown("by **scStudio**")
    st.markdown("---")
    st.button("Chat history")
    st.button("Make my own games")
    st.button("Code a AI")
    st.button("Roblox has ban")
    st.markdown("---")
    st.markdown("scStudio<br>Free mode", unsafe_allow_html=True)

# Main content
st.title("ZEDA.AI")
st.markdown("<p style='text-align: right; color: #888;'>zeda0.5</p>", unsafe_allow_html=True)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏•‡πà‡∏≠‡∏á‡πÅ‡∏ä‡∏ó
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("type anythings..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("Loading..."):
            try:
                messages = [
                    {"role": "user", "parts": [msg["content"]]} if msg["role"] == "user" else
                    {"role": "model", "parts": [msg["content"]]}
                    for msg in st.session_state.messages
                ]
                response = model.generate_content(messages)
                st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
            except Exception as e:
                st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Key ‡∏à‡∏≤‡∏Å Environment variable
genai.configure(api_key=os.environ.get("GOOGLE_API_KEY"))
model = genai.GenerativeModel("gemini-2.5-flash")

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡πÅ‡∏≠‡∏õ
st.title("ü§ñ ‡πÅ‡∏≠‡∏õ AI ‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó")

# ‡∏™‡∏£‡πâ‡∏≤‡∏á History ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ä‡∏ó
if "messages" not in st.session_state:
    st.session_state.messages = []

# ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ä‡∏ó‡πÉ‡∏ô History
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ‡∏£‡∏±‡∏ö Input ‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
if prompt := st.chat_input("‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏≠‡∏¢‡∏≤‡∏Å‡∏ñ‡∏≤‡∏°‡∏ú‡∏°‡πÑ‡∏´‡∏°?"):
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏•‡∏á‡πÉ‡∏ô Session State
    st.session_state.messages.append({"role": "user", "content": prompt})
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
    with st.chat_message("user"):
        st.markdown(prompt)

    # ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏õ‡∏´‡∏≤ AI
    with st.chat_message("assistant"):
        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö..."):
            try:
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ (History) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡∏à‡∏î‡∏à‡∏≥
                messages = [
                    {"role": "user", "parts": [msg["content"]]} if msg["role"] == "user" else 
                    {"role": "model", "parts": [msg["content"]]}
                    for msg in st.session_state.messages
                ]
                
                # ‡∏™‡πà‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
                response = model.generate_content(messages)
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                st.markdown(response.text)
                
                # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏≠‡∏á AI ‡∏•‡∏á‡πÉ‡∏ô Session State
                st.session_state.messages.append({"role": "assistant", "content": response.text})
            except Exception as e:
                st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
